{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HACKER NEWS PROJECT\n",
    "\n",
    "In this project, we will work with a dataset of submissions to the popular technology site Hacker News."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has the following entries\n",
    "\n",
    "1) id : The unique identifier from Hacker News for the post\n",
    "\n",
    "2) title : The title of the post\n",
    "\n",
    "3) url : The URL that the posts links to, if the post has a URL\n",
    "\n",
    "4) num_points: The mumber of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "\n",
    "5) num_comments : The number of comments that were made on the post\n",
    "\n",
    "6) author: The username of the person who submitted the post\n",
    "\n",
    "\n",
    "7) The date and time at which the post was submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are mostly interested in two types of posts, the Ask HN post and the Show HN posts.\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "1) Do 'Ask HN' or 'Show HN' recieve more comments on average?\n",
    "\n",
    "2) Do posts created at a certain time receive more comments on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE WILL WRITE A FUNCTION THAT WILL ENABLE US TO OPEN AND READ OUR CSV FILE, THIS FUNCTION WILL TAKE IN JUST ONE ARGUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(sets):\n",
    "    opened_file = open(sets, encoding = \"utf8\")\n",
    "    from csv import reader\n",
    "    read_file = reader(opened_file)\n",
    "    apps_data = list(read_file)\n",
    "    return apps_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW, WE CALL OUR FUNCTION AND ASSIGN IT TO A VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackers = data(\"C:\\\\Users\\\\USER\\\\Videos\\\\Coding Videos\\\\my_datasets\\\\hackers.csv\")\n",
    "hackers_header = hackers[0]\n",
    "hackers = hackers[1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE WRITE A FUNCTION THAT MAKES DATA EXPLORATION EASIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n",
      "Number of rows: 20100\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "def explore(sets, start, end, rows_and_columns = True):\n",
    "    data_slice = sets[start:end]\n",
    "    for row in data_slice:\n",
    "        print(row)\n",
    "        print(\"\\n\")\n",
    "    if rows_and_columns:\n",
    "        print(\"Number of rows:\", len(sets))\n",
    "        print(\"Number of columns:\", len(sets[0]))\n",
    "print(hackers_header)\n",
    "print(\"\\n\")\n",
    "explore(hackers, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE, WE DISTINGUISH ASK POSTS, SHOW POSTS AND OTHER POSTS FROM EACH OTHER. AND ASSIGN EACH TO AN EMPTY LIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ask post: 1744\n",
      "\n",
      "\n",
      "Number of ask post: 1162\n",
      "\n",
      "\n",
      "Number of ask post: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for row in hackers:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "print(\"Number of ask post:\", len(ask_posts))\n",
    "print(\"\\n\")\n",
    "print(\"Number of show post:\", len(show_posts))\n",
    "print(\"\\n\")\n",
    "print(\"Number of other post:\", len(other_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "\n",
      "\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "\n",
      "\n",
      "['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14']\n",
      "\n",
      "\n",
      "['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20']\n",
      "\n",
      "\n",
      "['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']\n",
      "\n",
      "\n",
      "Number of rows: 1744\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "explore(ask_posts, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "\n",
      "\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "\n",
      "\n",
      "['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']\n",
      "\n",
      "\n",
      "['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']\n",
      "\n",
      "\n",
      "['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']\n",
      "\n",
      "\n",
      "Number of rows: 1162\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "explore(show_posts, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since we are only consider show posts and asks post, we have to find the average comments on each posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "\n",
      "\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_ask_com = int(row[4])\n",
    "    total_ask_comments += num_ask_com\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "    \n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_show_com = int(row[4])\n",
    "    total_show_comments += num_show_com\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "\n",
    "print(avg_ask_comments)\n",
    "print(\"\\n\")\n",
    "print(avg_show_comments)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that ask posts has more comments on average than show posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ask posts receive or has more comments on average, we will focus our analysis on just ask posts.\n",
    "\n",
    "# Next, we will determine if ask posts created at a particular time are more likely to attract comments. To perform this analysis, we will use the following steps:\n",
    "\n",
    "1) Calculate the amount of ask posts created in each hour of the day, along with the number of comments received\n",
    "\n",
    "2) Calculate the average number of comments ask posts receive by hour created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "\n",
      "\n",
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "for row in result_list:\n",
    "    created_at = row[0]\n",
    "    num_comments =row[1]\n",
    "    date = dt.datetime.strptime(created_at, date_format)\n",
    "    hour = date.strftime(\"%H\")\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour]+=1\n",
    "    else:\n",
    "        counts_by_hour[hour]=1\n",
    "    if hour in comments_by_hour:\n",
    "        comments_by_hour[hour]+=num_comments\n",
    "    else:\n",
    "        comments_by_hour[hour] = num_comments\n",
    "        \n",
    "print(counts_by_hour)\n",
    "print(\"\\n\")\n",
    "print(comments_by_hour)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple', 20], ['banana', 40], ['orange', 60]]\n"
     ]
    }
   ],
   "source": [
    "sample_dicts = {\n",
    "    \"apple\" : 2,\n",
    "    \"banana\" : 4,\n",
    "    \"orange\" : 6\n",
    "}\n",
    "#Suppose we wanted to multiply each of the values by ten and return the results as list of list, this is how we will go about it\n",
    "\n",
    "fruits= []\n",
    "for fruit in sample_dicts:\n",
    "    fruits.append([fruit, 10*sample_dicts[fruit]])\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method is what we will use to obtain the average number ask post obtain by hour created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we will use the two dictionaries we created above to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959], ['17', 11.46], ['15', 38.5948275862069], ['21', 16.009174311926607], ['20', 21.525], ['02', 23.810344827586206], ['18', 13.20183486238532], ['03', 7.796296296296297], ['05', 10.08695652173913], ['19', 10.8], ['01', 11.383333333333333], ['22', 6.746478873239437], ['08', 10.25], ['04', 7.170212765957447], ['00', 8.127272727272727], ['06', 9.022727272727273], ['07', 7.852941176470588], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, we have obtained values for the average comments corresponding to post created at a particular hour, but from these values,it is difficult to identify easily the hour with most comments on average.\n",
    "\n",
    "Now, we will finish off by sorting out the five highest values in a format that easier to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SORTING OUT THE FIVE HIGHEST VALUES IN AN UNDERSTANDABLE FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.5948275862069, '15'], [23.810344827586206, '02'], [21.525, '20'], [16.796296296296298, '16'], [16.009174311926607, '21'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [13.20183486238532, '18'], [11.46, '17'], [11.383333333333333, '01'], [11.051724137931034, '11'], [10.8, '19'], [10.25, '08'], [10.08695652173913, '05'], [9.41095890410959, '12'], [9.022727272727273, '06'], [8.127272727272727, '00'], [7.985294117647059, '23'], [7.852941176470588, '07'], [7.796296296296297, '03'], [7.170212765957447, '04'], [6.746478873239437, '22'], [5.5777777777777775, '09']]\n",
      "\n",
      "\n",
      "[[38.5948275862069, '15'], [23.810344827586206, '02'], [21.525, '20'], [16.796296296296298, '16'], [16.009174311926607, '21']]\n",
      "\n",
      "\n",
      "TOP 5 HOURS FOR ASK POST COMMENTS\n",
      "\n",
      "\n",
      "At 15:00: 38.59 average comments per post are obtained\n",
      "At 02:00: 23.81 average comments per post are obtained\n",
      "At 20:00: 21.52 average comments per post are obtained\n",
      "At 16:00: 16.80 average comments per post are obtained\n",
      "At 21:00: 16.01 average comments per post are obtained\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    hour = row[0]\n",
    "    avg_comment = row[1]\n",
    "    swap_avg_by_hour.append([avg_comment, hour])\n",
    "#print(swap_avg_by_hour)\n",
    "sorted_swap=sorted(swap_avg_by_hour, reverse = True)#since the average number of comments is the first column in swap_avg, sorting will be done on the avg number of comments values\n",
    "print(sorted_swap)\n",
    "print(\"\\n\")\n",
    "print(sorted_swap[:5])#This prints the top five hours for ask post comments\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"TOP 5 HOURS FOR ASK POST COMMENTS\")\n",
    "print(\"\\n\")\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = row [1]\n",
    "    avg_comments = row[0]\n",
    "    time = dt.datetime.strptime(hour,\"%H\")\n",
    "    time = time.strftime(\"%H:%M\")\n",
    "    print(\"At {}: {:.2f} average comments per post are obtained\" .format(time, avg_comments))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our analysis of Hacker News Posts, we are able to ascertain the post that generated more comments on average. we see also that in order to maximize the number of comments generated or obtained, posts should be created at 15:00 0r 3:00pm \n",
    "\n",
    "It is worth of not that the created time in the Hackers News Post was based on Eastern US Time zone. hence, to convert it to my time zone(West African Time Zone), I will add 5 hours to the Eastern US Time zone.\n",
    "\n",
    "That is to say,to generate more comments, the post will have to be created at 20:00 0r 8:00pm WEST AFRICAN TIME ZONE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTENSION QUESTIONS\n",
    "\n",
    "## DETERMINATION BETWEEN SHOW AND ASK POSTS, WHICH HAS MORE POINTS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total points for ask posts: 26268\n",
      "\n",
      "\n",
      "Total points for show posts: 32019\n",
      "\n",
      "\n",
      "Average points for ask post: 15.061926605504587\n",
      "\n",
      "\n",
      "Average points for show_posts: 27.555077452667813\n"
     ]
    }
   ],
   "source": [
    "total_ask_points = 0\n",
    "for row in ask_posts:\n",
    "    num_points = row[3]\n",
    "    total_ask_points += int(num_points)\n",
    "total_show_points= 0\n",
    "for row in show_posts:\n",
    "    num_points = row[3]\n",
    "    total_show_points+= int(num_points)\n",
    "    \n",
    "print(\"Total points for ask posts:\", total_ask_points)\n",
    "print(\"\\n\")\n",
    "print(\"Total points for show posts:\", total_show_points)\n",
    "\n",
    "avg_ask_posts = total_ask_points/len(ask_posts)\n",
    "avg_show_posts = total_show_points/len(show_posts)\n",
    "print(\"\\n\")\n",
    "print(\"Average points for ask post:\", avg_ask_posts)\n",
    "print(\"\\n\")\n",
    "print(\"Average points for show_posts:\", avg_show_posts)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, show posts derived more points on avearge than ask posts. Hence, we will focus our analysis on show posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETERMINE IF POSTS CREATED AT A CERTAIN TIME ARE MORE LIKELY TO RECEIVE MORE POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "\n",
      "\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "\n",
      "\n",
      "['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']\n",
      "\n",
      "\n",
      "['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']\n",
      "\n",
      "\n",
      "['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']\n",
      "\n",
      "\n",
      "Number of rows: 1162\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "explore(show_posts, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "\n",
      "\n",
      "{'14': 2187, '22': 1856, '18': 2215, '07': 494, '20': 1819, '05': 104, '16': 2634, '19': 1702, '15': 2228, '03': 679, '17': 2521, '06': 375, '02': 340, '13': 2438, '08': 519, '21': 866, '04': 386, '11': 1480, '12': 2543, '23': 1526, '09': 553, '01': 700, '10': 681, '00': 1173}\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for row in show_posts:\n",
    "    created_at = row[6]\n",
    "    num_points = int(row[3])\n",
    "    result.append([created_at, num_points])\n",
    "count_by_hour = {}\n",
    "points_by_hour ={}\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "import datetime as dt\n",
    "for row in result:\n",
    "    created_at = row[0]\n",
    "    num_points = row[1]\n",
    "    time = dt.datetime.strptime(created_at, date_format)\n",
    "    hour = time.strftime(\"%H\")\n",
    "    if hour in count_by_hour:\n",
    "        count_by_hour[hour]+=1\n",
    "    else:\n",
    "        count_by_hour[hour] = 1\n",
    "    if hour in points_by_hour:\n",
    "        points_by_hour[hour] += num_points\n",
    "    else:\n",
    "        points_by_hour[hour] = num_points\n",
    "print(counts_by_hour)\n",
    "print(\"\\n\")\n",
    "print(points_by_hour)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DETERMINATION OF AVERAGE POINTS PER POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['14', 20.439252336448597], ['22', 26.140845070422536], ['18', 20.321100917431192], ['07', 14.529411764705882], ['20', 22.7375], ['05', 2.260869565217391], ['16', 24.38888888888889], ['19', 15.472727272727273], ['15', 19.20689655172414], ['03', 12.574074074074074], ['17', 25.21], ['06', 8.522727272727273], ['02', 5.862068965517241], ['13', 28.68235294117647], ['08', 10.8125], ['21', 7.944954128440367], ['04', 8.212765957446809], ['11', 25.517241379310345], ['12', 34.83561643835616], ['23', 22.441176470588236], ['09', 12.28888888888889], ['01', 11.666666666666666], ['10', 11.542372881355933], ['00', 21.327272727272728]]\n"
     ]
    }
   ],
   "source": [
    "avg_points = []\n",
    "for hour in points_by_hour:\n",
    "    avg_points.append([hour, points_by_hour[hour]/counts_by_hour[hour]])\n",
    "print(avg_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data looks alittle bit haphazard, so it has to be sorted. It will be sorted in descending order of the average points per post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34.83561643835616, '12'], [28.68235294117647, '13'], [26.140845070422536, '22'], [25.517241379310345, '11'], [25.21, '17'], [24.38888888888889, '16'], [22.7375, '20'], [22.441176470588236, '23'], [21.327272727272728, '00'], [20.439252336448597, '14'], [20.321100917431192, '18'], [19.20689655172414, '15'], [15.472727272727273, '19'], [14.529411764705882, '07'], [12.574074074074074, '03'], [12.28888888888889, '09'], [11.666666666666666, '01'], [11.542372881355933, '10'], [10.8125, '08'], [8.522727272727273, '06'], [8.212765957446809, '04'], [7.944954128440367, '21'], [5.862068965517241, '02'], [2.260869565217391, '05']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_points = []\n",
    "for row in avg_points:\n",
    "    swap_avg_points.append([row[1], row[0]])\n",
    "sorted_swap = sorted(swap_avg_points, reverse = True)\n",
    "print(sorted_swap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPRESENTING THE DATA IN AN UNDERSTANDABLE FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 12:00: 34.84 average points per posts are obtained\n",
      "At 13:00: 28.68 average points per posts are obtained\n",
      "At 22:00: 26.14 average points per posts are obtained\n",
      "At 11:00: 25.52 average points per posts are obtained\n",
      "At 17:00: 25.21 average points per posts are obtained\n"
     ]
    }
   ],
   "source": [
    "for row in sorted_swap[:5]:\n",
    "    avg_points = row[0]\n",
    "    hour = row[1]\n",
    "    time = dt.datetime.strptime(hour, \"%H\")\n",
    "    time = time.strftime(\"%H:%M\")\n",
    "    print(\"At {}: {:.2f} average points per posts are obtained\" . format(time, avg_points))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
